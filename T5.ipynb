{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==3.2.0 -q\n",
        "!pip install sentencepiece -q"
      ],
      "metadata": {
        "id": "6MY-e6dU6oWD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "P4L_P0Rl-o2r",
        "outputId": "2e1d3067-f530-4269-b209-153e7474a7eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.2.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "irs63_qs6hW7"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "# the following 2 hyperparameters are task-specific\n",
        "max_source_length = 512\n",
        "max_target_length = 128\n",
        "\n",
        "# Suppose we have the following 2 training examples:\n",
        "input_sequence_1 = \"Welcome to NYC; how are doing\"\n",
        "output_sequence_1 = \"How welcome are you in NYC\"\n",
        "\n",
        "input_sequence_2 = \"HuggingFace is a company; we are people\"\n",
        "output_sequence_2 = \"We are people in Huggingface company\"\n",
        "\n",
        "# encode the inputs\n",
        "task_prefix = \"mix two sentences: \"\n",
        "input_sequences = [input_sequence_1, input_sequence_2]\n",
        "\n",
        "encoding = tokenizer(\n",
        "    [task_prefix + sequence for sequence in input_sequences],\n",
        "    padding=\"longest\",\n",
        "    max_length=max_source_length,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "\n",
        "input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
        "\n",
        "# encode the targets\n",
        "target_encoding = tokenizer(\n",
        "    [output_sequence_1, output_sequence_2],\n",
        "    padding=\"longest\",\n",
        "    max_length=max_target_length,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "labels = target_encoding.input_ids\n",
        "\n",
        "# replace padding token id's of the labels by -100 so it's ignored by the loss\n",
        "labels[labels == tokenizer.pad_token_id] = -100"
      ],
      "metadata": {
        "id": "_FKk--d860Cm"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(attention_mask.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQiNQREx_wLu",
        "outputId": "1cb6b621-5e20-43e5-a632-a8571f8e9900"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 17])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy_ukjWd_-vy",
        "outputId": "32a013e0-9d14-40f9-a7e1-d17debbbee1c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipPUbLt3ABop",
        "outputId": "293b4d76-0442-4739-e1cb-f85f8a25a903"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  571,  2222,    33,    25,    16, 13465,     1,  -100,  -100],\n",
              "        [  101,    33,   151,    16, 11560,  3896,  4861,   349,     1]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass\n",
        "loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)"
      ],
      "metadata": {
        "id": "tq7yh6YqAUgp"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss[0], loss[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKEdQrDAAnZ2",
        "outputId": "6251342e-0277-483a-dbac-17c170ac6b9b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(4.1771, grad_fn=<NllLossBackward0>), torch.Size([2, 9, 32128]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(loss[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnRVPh0YBOsp",
        "outputId": "3c6d8cb0-cc80-4d46-911b-6cf24d53a8c3"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss[0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyI-rpf0AiPv",
        "outputId": "da0650ab-8136-432d-d707-451eb53a28dd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.177064418792725"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(\"mix two sentences: Who are these people?; we are going\", return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "w_fN0FvN_NT_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(input_ids)"
      ],
      "metadata": {
        "id": "1CMOnWsfB0Pn"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thd66FhsB2H9",
        "outputId": "69c29f61-e88d-45ea-9ea4-510df2c77f95"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ": Who are these people?; we are going\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3iVosACfB2zK"
      },
      "execution_count": 47,
      "outputs": []
    }
  ]
}